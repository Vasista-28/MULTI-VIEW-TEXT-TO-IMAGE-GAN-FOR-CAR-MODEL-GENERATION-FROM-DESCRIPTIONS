# MULTI-VIEW-TEXT-TO-IMAGE-GAN-FOR-CAR-MODEL-GENERATION-FROM-DESCRIPTIONS

## Overview
#### This project implements a Multi-view Text-to-Image Generative Adversarial Network (GAN) capable of generating top, front, and side views of cars from a single descriptive text input. The approach combines advanced rendering techniques, robust text embeddings, and state-of-the-art GAN architecture to bridge the gap between static single-view image generation and computationally expensive 3D modeling.

## Features
#### **Multi-view Image Generation:** Produces top, front, and side views from a single text description.
#### **Self-Attention Mechanisms:** Ensures feature alignment and consistency across generated perspectives.
#### **Semantic Understanding:** Utilizes BERT embeddings for accurate text-to-image mapping.
#### **Lightweight 2D Approximation:** Provides a scalable alternative to 3D modeling for visualization and prototyping.
